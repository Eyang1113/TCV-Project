{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tRgtHSRTaBs",
        "outputId": "70497ccb-7c36-454f-c39b-12857a77c488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset without pre processing**"
      ],
      "metadata": {
        "id": "nECHe4I2-UR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "# Load images without preprocessing\n",
        "def load_data(data_dir):\n",
        "    X = []  # Features (raw images)\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image to maintain consistent dimensions\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = img.flatten()  # Convert to 1D vector\n",
        "\n",
        "            X.append(img)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "X_train, y_train = load_data(data_dir_train)\n",
        "X_test, y_test = load_data(data_dir_test)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 3  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK4ULNy9XSj1",
        "outputId": "a6435c52-6b2a-4c33-86e4-3abe18d4f241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.38461538461538464\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.08      0.13        13\n",
            "           1       0.55      0.50      0.52        22\n",
            "           2       0.27      0.47      0.34        17\n",
            "\n",
            "    accuracy                           0.38        52\n",
            "   macro avg       0.44      0.35      0.33        52\n",
            "weighted avg       0.44      0.38      0.37        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing**"
      ],
      "metadata": {
        "id": "gyl2Rg5o-dgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            color_features = extract_color_histogram(img)\n",
        "            texture_features = extract_texture_features(img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 3  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqxf3aS2Wt-y",
        "outputId": "d4f8c651-fb3e-430d-fe4a-32ba8a75591f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7307692307692307\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.08      0.14        13\n",
            "           1       0.62      0.91      0.74        22\n",
            "           2       0.89      1.00      0.94        17\n",
            "\n",
            "    accuracy                           0.73        52\n",
            "   macro avg       0.84      0.66      0.61        52\n",
            "weighted avg       0.81      0.73      0.66        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing (img_sharpen)**"
      ],
      "metadata": {
        "id": "Pby5muFrZwMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "def sharpen_image(img):\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    # Sharpen the image\n",
        "    sharpened_image = cv2.filter2D(img, -1, kernel)\n",
        "    return sharpened_image\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_sharpen = sharpen_image(img)\n",
        "            color_features = extract_color_histogram(img_sharpen)\n",
        "            texture_features = extract_texture_features(img_sharpen)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 3  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4RUhhMuYb4E",
        "outputId": "b2fa001d-fa33-4340-f06e-886c57ddd982"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.08      0.14        13\n",
            "           1       0.64      0.95      0.76        22\n",
            "           2       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.75        52\n",
            "   macro avg       0.86      0.68      0.63        52\n",
            "weighted avg       0.83      0.75      0.68        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing (img_enhance)**"
      ],
      "metadata": {
        "id": "JxM61mRdZ52u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "def enhance_image(img):\n",
        "    enhance_img = cv2.convertScaleAbs(img, alpha=1.5, beta=20)\n",
        "    return enhance_img\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_enhance = enhance_image(img)\n",
        "            color_features = extract_color_histogram(img_enhance)\n",
        "            texture_features = extract_texture_features(img_enhance)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 3  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUaLoosUZPEr",
        "outputId": "1417817a-518b-4028-c3d3-27ee35c9990d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.08      0.14        13\n",
            "           1       0.66      0.95      0.78        22\n",
            "           2       0.89      1.00      0.94        17\n",
            "\n",
            "    accuracy                           0.75        52\n",
            "   macro avg       0.85      0.68      0.62        52\n",
            "weighted avg       0.82      0.75      0.67        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing (remove_bg)**"
      ],
      "metadata": {
        "id": "RI-ZwROuaD8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "def remove_background(img):\n",
        "    # Convert to grayscale and apply binary thresholding\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Create mask for grabCut\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    mask[binary_mask == 255] = cv2.GC_PR_BGD\n",
        "    mask[binary_mask == 0] = cv2.GC_PR_FGD\n",
        "\n",
        "    # Define models\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Run grabCut with the new mask\n",
        "    cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    # Modify mask to extract foreground\n",
        "    mask2 = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1).astype('uint8')\n",
        "    img_bg_removed = img * mask2[:, :, np.newaxis]\n",
        "\n",
        "    return img_bg_removed\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            remove_background_img = remove_background(img)\n",
        "            color_features = extract_color_histogram(remove_background_img)\n",
        "            texture_features = extract_texture_features(remove_background_img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 3  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9bAfZKnZgrM",
        "outputId": "f69041bd-d7f2-4a9b-e2e9-cf87b62df7ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.15      0.27        13\n",
            "           1       0.64      0.95      0.76        22\n",
            "           2       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.75        52\n",
            "   macro avg       0.86      0.68      0.66        52\n",
            "weighted avg       0.83      0.75      0.70        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset without pre processing**"
      ],
      "metadata": {
        "id": "_VQbnAekEfd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "# Load images without preprocessing\n",
        "def load_data(data_dir):\n",
        "    X = []  # Features (raw images)\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image to maintain consistent dimensions\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = img.flatten()  # Convert to 1D vector\n",
        "\n",
        "            X.append(img)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "X_train, y_train = load_data(data_dir_train)\n",
        "X_test, y_test = load_data(data_dir_test)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 5  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvISdFCoEkLA",
        "outputId": "90d9d0cc-e0f4-4990-911b-323c7189fada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5115489130434783\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.86      0.77      1071\n",
            "           1       0.40      0.35      0.38       669\n",
            "           2       0.39      0.45      0.42       827\n",
            "           3       0.45      0.47      0.46       989\n",
            "           4       0.52      0.30      0.39       860\n",
            "\n",
            "    accuracy                           0.51      4416\n",
            "   macro avg       0.49      0.49      0.48      4416\n",
            "weighted avg       0.51      0.51      0.50      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing**"
      ],
      "metadata": {
        "id": "wTXUvroDMG4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            color_features = extract_color_histogram(img)\n",
        "            texture_features = extract_texture_features(img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 5  # Number of neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faS9i90PJBIO",
        "outputId": "ffb1b7d3-0cbd-4ff7-80f5-019816aef7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.734375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88      1071\n",
            "           1       0.68      0.62      0.65       669\n",
            "           2       0.67      0.71      0.69       827\n",
            "           3       0.67      0.66      0.66       989\n",
            "           4       0.75      0.74      0.74       860\n",
            "\n",
            "    accuracy                           0.73      4416\n",
            "   macro avg       0.73      0.72      0.72      4416\n",
            "weighted avg       0.73      0.73      0.73      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing (img_sharpen)**"
      ],
      "metadata": {
        "id": "yLMUW7PCfxcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "def sharpen_image(img):\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    # Sharpen the image\n",
        "    sharpened_image = cv2.filter2D(img, -1, kernel)\n",
        "    return sharpened_image\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_sharpen = sharpen_image(img)\n",
        "            color_features = extract_color_histogram(img_sharpen)\n",
        "            texture_features = extract_texture_features(img_sharpen)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "print(\"Loading training data...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 5  # Number of neighbors\n",
        "print(\"Training the KNN model...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions...\")\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A87Zk4DTagIF",
        "outputId": "899860f3-991f-4e2e-fb79-a492cee2c02e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7368659420289855\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88      1071\n",
            "           1       0.69      0.59      0.63       669\n",
            "           2       0.68      0.72      0.70       827\n",
            "           3       0.65      0.68      0.67       989\n",
            "           4       0.78      0.73      0.75       860\n",
            "\n",
            "    accuracy                           0.74      4416\n",
            "   macro avg       0.73      0.72      0.73      4416\n",
            "weighted avg       0.74      0.74      0.74      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing (img_enhance)**\n",
        "\n"
      ],
      "metadata": {
        "id": "VARfsL2af2-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "def enhance_image(img):\n",
        "    enhance_img = cv2.convertScaleAbs(img, alpha=1.5, beta=20)\n",
        "    return enhance_img\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_enhance = enhance_image(img)\n",
        "            color_features = extract_color_histogram(img_enhance)\n",
        "            texture_features = extract_texture_features(img_enhance)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "print(\"Loading training data...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 5  # Number of neighbors\n",
        "print(\"Training the KNN model...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions...\")\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHkMv9WGf2RV",
        "outputId": "89a4a391-7c6f-4271-bca9-b6ac4d2b4719"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Loading testing data...\n",
            "Training the KNN model...\n",
            "Making predictions...\n",
            "Accuracy: 0.6788949275362319\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      1071\n",
            "           1       0.68      0.59      0.63       669\n",
            "           2       0.63      0.67      0.65       827\n",
            "           3       0.56      0.59      0.57       989\n",
            "           4       0.64      0.58      0.61       860\n",
            "\n",
            "    accuracy                           0.68      4416\n",
            "   macro avg       0.67      0.67      0.67      4416\n",
            "weighted avg       0.68      0.68      0.68      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing (remove_bg)**"
      ],
      "metadata": {
        "id": "SyfaJbyAhQOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Image resizing dimensions\n",
        "\n",
        "def remove_background(img):\n",
        "    # Convert to grayscale and apply binary thresholding\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Create mask for grabCut\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    mask[binary_mask == 255] = cv2.GC_PR_BGD\n",
        "    mask[binary_mask == 0] = cv2.GC_PR_FGD\n",
        "\n",
        "    # Define models\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Run grabCut with the new mask\n",
        "    cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    # Modify mask to extract foreground\n",
        "    mask2 = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1).astype('uint8')\n",
        "    img_bg_removed = img * mask2[:, :, np.newaxis]\n",
        "\n",
        "    return img_bg_removed\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            remove_background_img = remove_background(img)\n",
        "            color_features = extract_color_histogram(remove_background_img)\n",
        "            texture_features = extract_texture_features(remove_background_img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load and preprocess the data\n",
        "print(\"Loading training data...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train KNN model\n",
        "k = 5  # Number of neighbors\n",
        "print(\"Training the KNN model...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions...\")\n",
        "y_pred = knn_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qykddEJphWZc",
        "outputId": "e2f182f0-2e9b-48b0-d2b2-7613f3db8874"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Loading testing data...\n",
            "Training the KNN model...\n",
            "Making predictions...\n",
            "Accuracy: 0.6698369565217391\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87      1071\n",
            "           1       0.66      0.58      0.62       669\n",
            "           2       0.62      0.66      0.64       827\n",
            "           3       0.55      0.58      0.56       989\n",
            "           4       0.63      0.58      0.61       860\n",
            "\n",
            "    accuracy                           0.67      4416\n",
            "   macro avg       0.66      0.66      0.66      4416\n",
            "weighted avg       0.67      0.67      0.67      4416\n",
            "\n"
          ]
        }
      ]
    }
  ]
}