{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uz-rHj_ag1pN",
        "9oBJL3z09vWt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y39QkSB9VYRh",
        "outputId": "561e8452-7d87-4803-d8c0-31a87b6eae0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset without pre processing**"
      ],
      "metadata": {
        "id": "JdWAYZMZgVIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "# Load images without preprocessing\n",
        "def load_data(data_dir):\n",
        "    X = []  # Features (raw images)\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image to maintain consistent dimensions\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = img.flatten()  # Convert to 1D vector\n",
        "\n",
        "            X.append(img)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data(data_dir_test)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heQueVV0wsqw",
        "outputId": "f069e83e-7701-4fea-c53c-942dc72a9035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.5961538461538461\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.23      0.38        13\n",
            "           1       0.68      0.68      0.68        22\n",
            "           2       0.48      0.76      0.59        17\n",
            "\n",
            "    accuracy                           0.60        52\n",
            "   macro avg       0.72      0.56      0.55        52\n",
            "weighted avg       0.70      0.60      0.58        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing**"
      ],
      "metadata": {
        "id": "xSACvZ75gkhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            color_features = extract_color_histogram(img)\n",
        "            texture_features = extract_texture_features(img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRPDmoZLyPer",
        "outputId": "e79c71c6-f700-43ca-ab4e-6ef2eeba5d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.8461538461538461\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.38      0.56        13\n",
            "           1       0.73      1.00      0.85        22\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.85        52\n",
            "   macro avg       0.91      0.79      0.80        52\n",
            "weighted avg       0.89      0.85      0.82        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing (img_sharpen)**"
      ],
      "metadata": {
        "id": "AqqHuC6ej_b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "def sharpen_image(img):\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    # Sharpen the image\n",
        "    sharpened_image = cv2.filter2D(img, -1, kernel)\n",
        "    return sharpened_image\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_sharpen = sharpen_image(img)\n",
        "            color_features = extract_color_histogram(img_sharpen)\n",
        "            texture_features = extract_texture_features(img_sharpen)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5M1JsvokB5H",
        "outputId": "c1919687-5cde-43ca-e4ec-edeadf815a5d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.8076923076923077\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.23      0.38        13\n",
            "           1       0.69      1.00      0.81        22\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.81        52\n",
            "   macro avg       0.90      0.74      0.73        52\n",
            "weighted avg       0.87      0.81      0.77        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing (img_enhance)**"
      ],
      "metadata": {
        "id": "ZxCBzNmPklJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "def enhance_image(img):\n",
        "    enhance_img = cv2.convertScaleAbs(img, alpha=1.5, beta=20)\n",
        "    return enhance_img\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_enhance = enhance_image(img)\n",
        "            color_features = extract_color_histogram(img_enhance)\n",
        "            texture_features = extract_texture_features(img_enhance)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAxaiAL0knh5",
        "outputId": "6ae15b5d-96c3-44b1-97da-8c481bb003dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.9807692307692307\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        13\n",
            "           1       0.96      1.00      0.98        22\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.98        52\n",
            "   macro avg       0.99      0.97      0.98        52\n",
            "weighted avg       0.98      0.98      0.98        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self Collect Dataset with pre processing (remove_bg)**"
      ],
      "metadata": {
        "id": "EWNIxcYvk0OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Label/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Label/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "def remove_background(img):\n",
        "    # Convert to grayscale and apply binary thresholding\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Create mask for grabCut\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    mask[binary_mask == 255] = cv2.GC_PR_BGD\n",
        "    mask[binary_mask == 0] = cv2.GC_PR_FGD\n",
        "\n",
        "    # Define models\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Run grabCut with the new mask\n",
        "    cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    # Modify mask to extract foreground\n",
        "    mask2 = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1).astype('uint8')\n",
        "    img_bg_removed = img * mask2[:, :, np.newaxis]\n",
        "\n",
        "    return img_bg_removed\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            remove_background_img = remove_background(img)\n",
        "            color_features = extract_color_histogram(remove_background_img)\n",
        "            texture_features = extract_texture_features(remove_background_img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCqdbpjqk3gt",
        "outputId": "f11e45c1-3dfc-4454-f3d5-be977cfe96d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.8269230769230769\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.31      0.47        13\n",
            "           1       0.73      1.00      0.85        22\n",
            "           2       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.83        52\n",
            "   macro avg       0.89      0.77      0.76        52\n",
            "weighted avg       0.87      0.83      0.79        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset without pre processing**"
      ],
      "metadata": {
        "id": "uz-rHj_ag1pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "# Load images without preprocessing\n",
        "def load_data(data_dir):\n",
        "    X = []  # Features (raw images)\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image to maintain consistent dimensions\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = img.flatten()  # Convert to 1D vector\n",
        "\n",
        "            X.append(img)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data(data_dir_test)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkOcC-19Xiaz",
        "outputId": "5731d41f-98ff-4f89-9b7e-b2cf250c42b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.6691576086956522\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83      1071\n",
            "           1       0.55      0.56      0.55       669\n",
            "           2       0.57      0.62      0.59       827\n",
            "           3       0.61      0.62      0.61       989\n",
            "           4       0.74      0.66      0.70       860\n",
            "\n",
            "    accuracy                           0.67      4416\n",
            "   macro avg       0.66      0.66      0.66      4416\n",
            "weighted avg       0.67      0.67      0.67      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing**"
      ],
      "metadata": {
        "id": "9oBJL3z09vWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            color_features = extract_color_histogram(img)\n",
        "            texture_features = extract_texture_features(img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVfTuF0cg3i7",
        "outputId": "4cc8ef1d-380b-4145-bf56-e257668e4cc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.7296195652173914\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      1071\n",
            "           1       0.73      0.64      0.68       669\n",
            "           2       0.70      0.72      0.71       827\n",
            "           3       0.62      0.68      0.65       989\n",
            "           4       0.71      0.65      0.68       860\n",
            "\n",
            "    accuracy                           0.73      4416\n",
            "   macro avg       0.73      0.72      0.72      4416\n",
            "weighted avg       0.73      0.73      0.73      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing (img_sharpen)**"
      ],
      "metadata": {
        "id": "1YhFWVVzBKNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "def sharpen_image(img):\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    # Sharpen the image\n",
        "    sharpened_image = cv2.filter2D(img, -1, kernel)\n",
        "    return sharpened_image\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_sharpen = sharpen_image(img)\n",
        "            color_features = extract_color_histogram(img_sharpen)\n",
        "            texture_features = extract_texture_features(img_sharpen)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxXIe_t6BP70",
        "outputId": "f736bcba-374a-4f10-fb76-c950bc4953ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.7284873188405797\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88      1071\n",
            "           1       0.72      0.59      0.65       669\n",
            "           2       0.68      0.72      0.70       827\n",
            "           3       0.62      0.67      0.64       989\n",
            "           4       0.76      0.68      0.71       860\n",
            "\n",
            "    accuracy                           0.73      4416\n",
            "   macro avg       0.73      0.71      0.72      4416\n",
            "weighted avg       0.73      0.73      0.73      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing (img_enhance)**"
      ],
      "metadata": {
        "id": "hmd7NU_0Bs7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "def enhance_image(img):\n",
        "    enhance_img = cv2.convertScaleAbs(img, alpha=1.5, beta=20)\n",
        "    return enhance_img\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            img_enhance = enhance_image(img)\n",
        "            color_features = extract_color_histogram(img_enhance)\n",
        "            texture_features = extract_texture_features(img_enhance)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VM_jeaSByqx",
        "outputId": "feeeedf7-b214-4b18-f90c-f0029d69fb96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.6788949275362319\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      1071\n",
            "           1       0.72      0.60      0.65       669\n",
            "           2       0.65      0.67      0.66       827\n",
            "           3       0.53      0.63      0.58       989\n",
            "           4       0.63      0.52      0.57       860\n",
            "\n",
            "    accuracy                           0.68      4416\n",
            "   macro avg       0.68      0.67      0.67      4416\n",
            "weighted avg       0.68      0.68      0.68      4416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public Dataset with pre processing (remove_bg)**"
      ],
      "metadata": {
        "id": "wnnVQdpNB_Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set paths\n",
        "data_dir_train = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/train\"\n",
        "data_dir_test = \"/content/drive/MyDrive/Hass Avocado Ripening Photographic Dataset/outfolder/test\"\n",
        "labels_dict = {\"Level1\": 0, \"Level2\": 1, \"Level3\": 2, \"Level4\": 3, \"Level5\": 4}\n",
        "\n",
        "# Feature extraction parameters\n",
        "COLOR_BINS = 32\n",
        "IMG_SIZE = (64, 64)  # Maintain resizing only for consistent input dimensions\n",
        "\n",
        "def remove_background(img):\n",
        "    # Convert to grayscale and apply binary thresholding\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Create mask for grabCut\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    mask[binary_mask == 255] = cv2.GC_PR_BGD\n",
        "    mask[binary_mask == 0] = cv2.GC_PR_FGD\n",
        "\n",
        "    # Define models\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Run grabCut with the new mask\n",
        "    cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    # Modify mask to extract foreground\n",
        "    mask2 = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1).astype('uint8')\n",
        "    img_bg_removed = img * mask2[:, :, np.newaxis]\n",
        "\n",
        "    return img_bg_removed\n",
        "\n",
        "# Extract color histogram features\n",
        "def extract_color_histogram(img):\n",
        "    hist = cv2.calcHist([img], [0, 1, 2], None, [COLOR_BINS, COLOR_BINS, COLOR_BINS], [0, 256, 0, 256, 0, 256])\n",
        "    return cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "# Placeholder for texture feature extraction (can be extended)\n",
        "def extract_texture_features(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_img.flatten()[:COLOR_BINS]  # Simplified feature example\n",
        "\n",
        "# Load images and extract features\n",
        "def load_data_and_extract_features(data_dir):\n",
        "    X = []  # Features\n",
        "    y = []  # Labels\n",
        "\n",
        "    for label_name, label_id in labels_dict.items():\n",
        "        class_dir = os.path.join(data_dir, label_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            # Extract features\n",
        "            remove_background_img = remove_background(img)\n",
        "            color_features = extract_color_histogram(remove_background_img)\n",
        "            texture_features = extract_texture_features(remove_background_img)\n",
        "            features = np.concatenate((color_features, texture_features))\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(label_id)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the train and test data\n",
        "print(\"Loading training data with resizing...\")\n",
        "X_train, y_train = load_data_and_extract_features(data_dir_train)\n",
        "print(\"Loading testing data with resizing...\")\n",
        "X_test, y_test = load_data_and_extract_features(data_dir_test)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=50)  # Adjust components as needed\n",
        "X_train_pca = pca.fit_transform(X_train_normalized)\n",
        "X_test_pca = pca.transform(X_test_normalized)\n",
        "\n",
        "# Create and train SVM model\n",
        "print(\"Training the SVM model with resizing...\")\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predictions\n",
        "print(\"Making predictions with resizing...\")\n",
        "y_pred = svm_model.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AggWWSyaCDAG",
        "outputId": "d7b04497-3e76-414c-8a7a-fafad19af364"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data with resizing...\n",
            "Loading testing data with resizing...\n",
            "Training the SVM model with resizing...\n",
            "Making predictions with resizing...\n",
            "Accuracy: 0.6748188405797102\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      1071\n",
            "           1       0.71      0.59      0.65       669\n",
            "           2       0.65      0.67      0.66       827\n",
            "           3       0.53      0.61      0.56       989\n",
            "           4       0.62      0.52      0.57       860\n",
            "\n",
            "    accuracy                           0.67      4416\n",
            "   macro avg       0.67      0.66      0.67      4416\n",
            "weighted avg       0.68      0.67      0.67      4416\n",
            "\n"
          ]
        }
      ]
    }
  ]
}